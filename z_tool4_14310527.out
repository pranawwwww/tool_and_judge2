‚úèÔ∏è Setting installed package as editable
Result file tool/result/ibm-granite-granite-4.0-h-small/pre_translate/["BFCL_v4_multiple","zh","fulltrans","nonoise"].jsonl does not exist, will be created.
For dataset file ["BFCL_v4_multiple","zh","fulltrans","nonoise"].jsonl, total entries: 200, existing entries: 0, missing entries: 200
Result file tool/result/ibm-granite-granite-4.0-h-small/pre_translate/["BFCL_v4_multiple","zh","fulltrans","para"].jsonl does not exist, will be created.
For dataset file ["BFCL_v4_multiple","zh","fulltrans","para"].jsonl, total entries: 200, existing entries: 0, missing entries: 200
Result file tool/result/ibm-granite-granite-4.0-h-small/pre_translate/["BFCL_v4_multiple","zh","fulltrans","syno"].jsonl does not exist, will be created.
For dataset file ["BFCL_v4_multiple","zh","fulltrans","syno"].jsonl, total entries: 200, existing entries: 0, missing entries: 200
Wrote aggregated questions to file: tool/result/ibm-granite-granite-4.0-h-small/pre_translate_aggregated_questions_input.jsonl
Acquiring build lock...
Building Rust extension with maturin develop...
Installed Rust extension successfully.
Released build lock.
Loading config from: tool_config_slurm4.py
Processing configuration:  <builtins.ToolConfig object at 0x7fb8c721ba70>
----------PASS 1: PRE-TRANSLATE QUESTIONS----------
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:22:14 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:22:14 [model.py:1750] Using max model len 5000
INFO 12-22 23:22:21 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:22:21 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:22:24 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:22:24 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=355773)[0;0m INFO 12-22 23:22:26 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=355773)[0;0m INFO 12-22 23:22:43 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:44697 backend=nccl
[0;36m(EngineCore_DP0 pid=355773)[0;0m INFO 12-22 23:22:44 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=355773)[0;0m INFO 12-22 23:22:45 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=355773)[0;0m INFO 12-22 23:22:46 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=355773)[0;0m INFO 12-22 23:22:48 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=355773)[0;0m ERROR 12-22 23:22:49 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:22:51 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:22:51 [model.py:1750] Using max model len 5000
INFO 12-22 23:22:51 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:22:51 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:22:51 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:22:51 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=355835)[0;0m INFO 12-22 23:22:53 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=355835)[0;0m INFO 12-22 23:22:54 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:55613 backend=nccl
[0;36m(EngineCore_DP0 pid=355835)[0;0m INFO 12-22 23:22:54 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=355835)[0;0m INFO 12-22 23:22:55 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=355835)[0;0m INFO 12-22 23:22:55 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=355835)[0;0m INFO 12-22 23:22:56 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=355835)[0;0m ERROR 12-22 23:22:56 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:22:58 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:22:58 [model.py:1750] Using max model len 5000
INFO 12-22 23:22:58 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:22:58 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:22:58 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:22:58 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=355897)[0;0m INFO 12-22 23:22:59 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=355897)[0;0m INFO 12-22 23:23:01 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:42433 backend=nccl
[0;36m(EngineCore_DP0 pid=355897)[0;0m INFO 12-22 23:23:01 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=355897)[0;0m INFO 12-22 23:23:01 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=355897)[0;0m INFO 12-22 23:23:01 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=355897)[0;0m INFO 12-22 23:23:02 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=355897)[0;0m ERROR 12-22 23:23:03 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:23:04 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:23:04 [model.py:1750] Using max model len 5000
INFO 12-22 23:23:04 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:23:04 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:23:04 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:23:04 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=356302)[0;0m INFO 12-22 23:23:04 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=356302)[0;0m INFO 12-22 23:23:06 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:34163 backend=nccl
[0;36m(EngineCore_DP0 pid=356302)[0;0m INFO 12-22 23:23:06 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=356302)[0;0m INFO 12-22 23:23:07 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=356302)[0;0m INFO 12-22 23:23:07 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=356302)[0;0m INFO 12-22 23:23:08 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356302)[0;0m ERROR 12-22 23:23:09 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:23:10 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:23:10 [model.py:1750] Using max model len 5000
INFO 12-22 23:23:10 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:23:10 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:23:10 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:23:10 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=356364)[0;0m INFO 12-22 23:23:11 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=356364)[0;0m INFO 12-22 23:23:12 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:43215 backend=nccl
[0;36m(EngineCore_DP0 pid=356364)[0;0m INFO 12-22 23:23:12 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=356364)[0;0m INFO 12-22 23:23:13 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=356364)[0;0m INFO 12-22 23:23:13 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=356364)[0;0m INFO 12-22 23:23:14 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356364)[0;0m ERROR 12-22 23:23:14 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:23:15 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:23:15 [model.py:1750] Using max model len 5000
INFO 12-22 23:23:15 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:23:15 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:23:15 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:23:15 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=356426)[0;0m INFO 12-22 23:23:16 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=356426)[0;0m INFO 12-22 23:23:17 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:34099 backend=nccl
[0;36m(EngineCore_DP0 pid=356426)[0;0m INFO 12-22 23:23:17 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=356426)[0;0m INFO 12-22 23:23:18 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=356426)[0;0m INFO 12-22 23:23:18 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=356426)[0;0m INFO 12-22 23:23:19 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356426)[0;0m ERROR 12-22 23:23:20 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:23:21 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:23:21 [model.py:1750] Using max model len 5000
INFO 12-22 23:23:21 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:23:21 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:23:21 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:23:21 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=356488)[0;0m INFO 12-22 23:23:21 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=356488)[0;0m INFO 12-22 23:23:23 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:39505 backend=nccl
[0;36m(EngineCore_DP0 pid=356488)[0;0m INFO 12-22 23:23:23 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=356488)[0;0m INFO 12-22 23:23:24 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=356488)[0;0m INFO 12-22 23:23:24 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=356488)[0;0m INFO 12-22 23:23:25 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356488)[0;0m ERROR 12-22 23:23:25 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:23:27 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:23:27 [model.py:1750] Using max model len 5000
INFO 12-22 23:23:27 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:23:27 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:23:27 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:23:27 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=356550)[0;0m INFO 12-22 23:23:28 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=356550)[0;0m INFO 12-22 23:23:29 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:34699 backend=nccl
[0;36m(EngineCore_DP0 pid=356550)[0;0m INFO 12-22 23:23:29 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=356550)[0;0m INFO 12-22 23:23:30 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=356550)[0;0m INFO 12-22 23:23:30 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=356550)[0;0m INFO 12-22 23:23:31 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356550)[0;0m ERROR 12-22 23:23:31 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:23:35 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:23:35 [model.py:1750] Using max model len 5000
INFO 12-22 23:23:35 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:23:35 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:23:35 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:23:35 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=356612)[0;0m INFO 12-22 23:23:36 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=356612)[0;0m INFO 12-22 23:23:38 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:43293 backend=nccl
[0;36m(EngineCore_DP0 pid=356612)[0;0m INFO 12-22 23:23:38 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=356612)[0;0m INFO 12-22 23:23:39 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=356612)[0;0m INFO 12-22 23:23:39 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=356612)[0;0m INFO 12-22 23:23:40 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356612)[0;0m ERROR 12-22 23:23:40 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:23:46 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:23:46 [model.py:1750] Using max model len 5000
INFO 12-22 23:23:46 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:23:46 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:23:46 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:23:46 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=356675)[0;0m INFO 12-22 23:23:47 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=356675)[0;0m INFO 12-22 23:23:49 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:44577 backend=nccl
[0;36m(EngineCore_DP0 pid=356675)[0;0m INFO 12-22 23:23:49 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=356675)[0;0m INFO 12-22 23:23:49 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=356675)[0;0m INFO 12-22 23:23:50 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=356675)[0;0m INFO 12-22 23:23:51 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356675)[0;0m ERROR 12-22 23:23:51 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:23:56 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:23:56 [model.py:1750] Using max model len 5000
INFO 12-22 23:23:56 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:23:56 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:23:56 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:23:56 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=356737)[0;0m INFO 12-22 23:23:58 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=356737)[0;0m INFO 12-22 23:24:00 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:50157 backend=nccl
[0;36m(EngineCore_DP0 pid=356737)[0;0m INFO 12-22 23:24:00 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=356737)[0;0m INFO 12-22 23:24:01 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=356737)[0;0m INFO 12-22 23:24:01 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=356737)[0;0m INFO 12-22 23:24:02 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=356737)[0;0m ERROR 12-22 23:24:03 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:24:04 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:24:04 [model.py:1750] Using max model len 5000
INFO 12-22 23:24:04 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:24:04 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:24:04 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:24:04 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=357143)[0;0m INFO 12-22 23:24:06 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=357143)[0;0m INFO 12-22 23:24:07 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:36715 backend=nccl
[0;36m(EngineCore_DP0 pid=357143)[0;0m INFO 12-22 23:24:07 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=357143)[0;0m INFO 12-22 23:24:08 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=357143)[0;0m INFO 12-22 23:24:08 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=357143)[0;0m INFO 12-22 23:24:09 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357143)[0;0m ERROR 12-22 23:24:09 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:24:12 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:24:12 [model.py:1750] Using max model len 5000
INFO 12-22 23:24:12 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:24:12 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:24:12 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:24:12 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=357205)[0;0m INFO 12-22 23:24:12 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=357205)[0;0m INFO 12-22 23:24:14 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:38335 backend=nccl
[0;36m(EngineCore_DP0 pid=357205)[0;0m INFO 12-22 23:24:14 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=357205)[0;0m INFO 12-22 23:24:15 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=357205)[0;0m INFO 12-22 23:24:15 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=357205)[0;0m INFO 12-22 23:24:16 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357205)[0;0m ERROR 12-22 23:24:16 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:24:19 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:24:19 [model.py:1750] Using max model len 5000
INFO 12-22 23:24:19 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:24:19 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:24:19 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:24:19 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=357267)[0;0m INFO 12-22 23:24:20 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=357267)[0;0m INFO 12-22 23:24:22 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:54991 backend=nccl
[0;36m(EngineCore_DP0 pid=357267)[0;0m INFO 12-22 23:24:22 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=357267)[0;0m INFO 12-22 23:24:22 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=357267)[0;0m INFO 12-22 23:24:23 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=357267)[0;0m INFO 12-22 23:24:24 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357267)[0;0m ERROR 12-22 23:24:24 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:24:29 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:24:29 [model.py:1750] Using max model len 5000
INFO 12-22 23:24:29 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:24:29 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:24:29 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:24:29 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=357330)[0;0m INFO 12-22 23:24:31 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=357330)[0;0m INFO 12-22 23:24:32 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:53875 backend=nccl
[0;36m(EngineCore_DP0 pid=357330)[0;0m INFO 12-22 23:24:33 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=357330)[0;0m INFO 12-22 23:24:33 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=357330)[0;0m INFO 12-22 23:24:33 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=357330)[0;0m INFO 12-22 23:24:34 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357330)[0;0m ERROR 12-22 23:24:35 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:24:38 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:24:38 [model.py:1750] Using max model len 5000
INFO 12-22 23:24:38 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:24:38 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:24:38 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:24:38 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=357392)[0;0m INFO 12-22 23:24:39 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=357392)[0;0m INFO 12-22 23:24:40 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:54665 backend=nccl
[0;36m(EngineCore_DP0 pid=357392)[0;0m INFO 12-22 23:24:40 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=357392)[0;0m INFO 12-22 23:24:41 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=357392)[0;0m INFO 12-22 23:24:41 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=357392)[0;0m INFO 12-22 23:24:42 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357392)[0;0m ERROR 12-22 23:24:42 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:24:45 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:24:45 [model.py:1750] Using max model len 5000
INFO 12-22 23:24:45 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:24:45 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:24:45 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:24:45 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=357454)[0;0m INFO 12-22 23:24:46 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=357454)[0;0m INFO 12-22 23:24:47 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:48199 backend=nccl
[0;36m(EngineCore_DP0 pid=357454)[0;0m INFO 12-22 23:24:48 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=357454)[0;0m INFO 12-22 23:24:48 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=357454)[0;0m INFO 12-22 23:24:48 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=357454)[0;0m INFO 12-22 23:24:49 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357454)[0;0m ERROR 12-22 23:24:50 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:24:51 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:24:51 [model.py:1750] Using max model len 5000
INFO 12-22 23:24:51 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:24:51 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:24:51 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:24:51 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=357516)[0;0m INFO 12-22 23:24:52 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=357516)[0;0m INFO 12-22 23:24:53 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:59357 backend=nccl
[0;36m(EngineCore_DP0 pid=357516)[0;0m INFO 12-22 23:24:53 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=357516)[0;0m INFO 12-22 23:24:54 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=357516)[0;0m INFO 12-22 23:24:54 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=357516)[0;0m INFO 12-22 23:24:55 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357516)[0;0m ERROR 12-22 23:24:56 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:24:57 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:24:57 [model.py:1750] Using max model len 5000
INFO 12-22 23:24:57 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:24:57 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:24:57 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:24:57 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=357578)[0;0m INFO 12-22 23:24:58 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=357578)[0;0m INFO 12-22 23:24:59 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:52941 backend=nccl
[0;36m(EngineCore_DP0 pid=357578)[0;0m INFO 12-22 23:24:59 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=357578)[0;0m INFO 12-22 23:25:00 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=357578)[0;0m INFO 12-22 23:25:00 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=357578)[0;0m INFO 12-22 23:25:01 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357578)[0;0m ERROR 12-22 23:25:02 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:25:04 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:25:04 [model.py:1750] Using max model len 5000
INFO 12-22 23:25:04 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:25:04 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:25:04 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:25:04 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=357986)[0;0m INFO 12-22 23:25:05 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=357986)[0;0m INFO 12-22 23:25:07 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:54893 backend=nccl
[0;36m(EngineCore_DP0 pid=357986)[0;0m INFO 12-22 23:25:07 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=357986)[0;0m INFO 12-22 23:25:07 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=357986)[0;0m INFO 12-22 23:25:08 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=357986)[0;0m INFO 12-22 23:25:08 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=357986)[0;0m ERROR 12-22 23:25:09 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:25:11 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:25:11 [model.py:1750] Using max model len 5000
INFO 12-22 23:25:11 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:25:11 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:25:11 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:25:11 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=358048)[0;0m INFO 12-22 23:25:12 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=358048)[0;0m INFO 12-22 23:25:13 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:32781 backend=nccl
[0;36m(EngineCore_DP0 pid=358048)[0;0m INFO 12-22 23:25:13 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=358048)[0;0m INFO 12-22 23:25:14 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=358048)[0;0m INFO 12-22 23:25:14 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=358048)[0;0m INFO 12-22 23:25:15 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358048)[0;0m ERROR 12-22 23:25:16 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:25:17 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:25:17 [model.py:1750] Using max model len 5000
INFO 12-22 23:25:17 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:25:17 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:25:17 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:25:17 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=358110)[0;0m INFO 12-22 23:25:17 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=358110)[0;0m INFO 12-22 23:25:19 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:34417 backend=nccl
[0;36m(EngineCore_DP0 pid=358110)[0;0m INFO 12-22 23:25:19 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=358110)[0;0m INFO 12-22 23:25:20 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=358110)[0;0m INFO 12-22 23:25:20 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=358110)[0;0m INFO 12-22 23:25:21 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358110)[0;0m ERROR 12-22 23:25:21 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:25:23 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:25:23 [model.py:1750] Using max model len 5000
INFO 12-22 23:25:23 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:25:23 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:25:23 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:25:23 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=358172)[0;0m INFO 12-22 23:25:23 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=358172)[0;0m INFO 12-22 23:25:25 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:44221 backend=nccl
[0;36m(EngineCore_DP0 pid=358172)[0;0m INFO 12-22 23:25:25 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=358172)[0;0m INFO 12-22 23:25:26 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=358172)[0;0m INFO 12-22 23:25:26 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=358172)[0;0m INFO 12-22 23:25:27 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358172)[0;0m ERROR 12-22 23:25:27 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:25:29 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:25:29 [model.py:1750] Using max model len 5000
INFO 12-22 23:25:29 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:25:29 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:25:29 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:25:29 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=358234)[0;0m INFO 12-22 23:25:30 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=358234)[0;0m INFO 12-22 23:25:31 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:51331 backend=nccl
[0;36m(EngineCore_DP0 pid=358234)[0;0m INFO 12-22 23:25:31 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=358234)[0;0m INFO 12-22 23:25:32 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=358234)[0;0m INFO 12-22 23:25:32 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=358234)[0;0m INFO 12-22 23:25:33 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358234)[0;0m ERROR 12-22 23:25:33 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:25:35 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:25:35 [model.py:1750] Using max model len 5000
INFO 12-22 23:25:35 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:25:35 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:25:35 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:25:35 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=358296)[0;0m INFO 12-22 23:25:36 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=358296)[0;0m INFO 12-22 23:25:37 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:43587 backend=nccl
[0;36m(EngineCore_DP0 pid=358296)[0;0m INFO 12-22 23:25:37 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=358296)[0;0m INFO 12-22 23:25:38 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=358296)[0;0m INFO 12-22 23:25:38 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=358296)[0;0m INFO 12-22 23:25:39 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358296)[0;0m ERROR 12-22 23:25:40 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:25:42 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:25:42 [model.py:1750] Using max model len 5000
INFO 12-22 23:25:42 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:25:42 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:25:42 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:25:42 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=358358)[0;0m INFO 12-22 23:25:43 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=358358)[0;0m INFO 12-22 23:25:45 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:47875 backend=nccl
[0;36m(EngineCore_DP0 pid=358358)[0;0m INFO 12-22 23:25:45 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=358358)[0;0m INFO 12-22 23:25:46 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=358358)[0;0m INFO 12-22 23:25:46 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=358358)[0;0m INFO 12-22 23:25:47 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358358)[0;0m ERROR 12-22 23:25:47 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:25:49 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:25:49 [model.py:1750] Using max model len 5000
INFO 12-22 23:25:49 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:25:49 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:25:49 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:25:49 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=358420)[0;0m INFO 12-22 23:25:50 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=358420)[0;0m INFO 12-22 23:25:51 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:58879 backend=nccl
[0;36m(EngineCore_DP0 pid=358420)[0;0m INFO 12-22 23:25:51 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=358420)[0;0m INFO 12-22 23:25:52 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=358420)[0;0m INFO 12-22 23:25:53 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=358420)[0;0m INFO 12-22 23:25:53 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358420)[0;0m ERROR 12-22 23:25:54 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:25:55 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:25:55 [model.py:1750] Using max model len 5000
INFO 12-22 23:25:55 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:25:55 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:25:55 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:25:55 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=358482)[0;0m INFO 12-22 23:25:56 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=358482)[0;0m INFO 12-22 23:25:58 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:39233 backend=nccl
[0;36m(EngineCore_DP0 pid=358482)[0;0m INFO 12-22 23:25:58 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=358482)[0;0m INFO 12-22 23:25:58 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=358482)[0;0m INFO 12-22 23:25:59 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=358482)[0;0m INFO 12-22 23:25:59 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358482)[0;0m ERROR 12-22 23:26:00 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:26:01 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:26:01 [model.py:1750] Using max model len 5000
INFO 12-22 23:26:01 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:26:01 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:26:01 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:26:01 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=358887)[0;0m INFO 12-22 23:26:02 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=358887)[0;0m INFO 12-22 23:26:03 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:53919 backend=nccl
[0;36m(EngineCore_DP0 pid=358887)[0;0m INFO 12-22 23:26:03 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=358887)[0;0m INFO 12-22 23:26:04 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=358887)[0;0m INFO 12-22 23:26:04 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=358887)[0;0m INFO 12-22 23:26:05 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358887)[0;0m ERROR 12-22 23:26:06 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:26:07 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:26:07 [model.py:1750] Using max model len 5000
INFO 12-22 23:26:07 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:26:07 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:26:07 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:26:07 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=358949)[0;0m INFO 12-22 23:26:08 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=358949)[0;0m INFO 12-22 23:26:09 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:52997 backend=nccl
[0;36m(EngineCore_DP0 pid=358949)[0;0m INFO 12-22 23:26:09 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=358949)[0;0m INFO 12-22 23:26:10 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=358949)[0;0m INFO 12-22 23:26:10 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=358949)[0;0m INFO 12-22 23:26:11 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=358949)[0;0m ERROR 12-22 23:26:12 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:26:13 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:26:13 [model.py:1750] Using max model len 5000
INFO 12-22 23:26:13 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:26:13 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:26:13 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:26:13 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=359011)[0;0m INFO 12-22 23:26:13 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=359011)[0;0m INFO 12-22 23:26:15 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:48193 backend=nccl
[0;36m(EngineCore_DP0 pid=359011)[0;0m INFO 12-22 23:26:15 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=359011)[0;0m INFO 12-22 23:26:16 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=359011)[0;0m INFO 12-22 23:26:16 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=359011)[0;0m INFO 12-22 23:26:17 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359011)[0;0m ERROR 12-22 23:26:18 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:26:19 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:26:19 [model.py:1750] Using max model len 5000
INFO 12-22 23:26:19 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:26:19 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:26:19 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:26:19 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=359073)[0;0m INFO 12-22 23:26:19 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=359073)[0;0m INFO 12-22 23:26:21 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:60453 backend=nccl
[0;36m(EngineCore_DP0 pid=359073)[0;0m INFO 12-22 23:26:21 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=359073)[0;0m INFO 12-22 23:26:21 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=359073)[0;0m INFO 12-22 23:26:22 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=359073)[0;0m INFO 12-22 23:26:22 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359073)[0;0m ERROR 12-22 23:26:23 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:26:24 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:26:24 [model.py:1750] Using max model len 5000
INFO 12-22 23:26:24 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:26:24 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:26:24 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:26:24 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=359135)[0;0m INFO 12-22 23:26:25 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=359135)[0;0m INFO 12-22 23:26:26 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:36443 backend=nccl
[0;36m(EngineCore_DP0 pid=359135)[0;0m INFO 12-22 23:26:26 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=359135)[0;0m INFO 12-22 23:26:27 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=359135)[0;0m INFO 12-22 23:26:28 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=359135)[0;0m INFO 12-22 23:26:28 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359135)[0;0m ERROR 12-22 23:26:29 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:26:30 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:26:30 [model.py:1750] Using max model len 5000
INFO 12-22 23:26:30 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:26:30 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:26:30 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:26:30 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=359197)[0;0m INFO 12-22 23:26:31 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=359197)[0;0m INFO 12-22 23:26:32 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:47169 backend=nccl
[0;36m(EngineCore_DP0 pid=359197)[0;0m INFO 12-22 23:26:32 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=359197)[0;0m INFO 12-22 23:26:33 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=359197)[0;0m INFO 12-22 23:26:33 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=359197)[0;0m INFO 12-22 23:26:34 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359197)[0;0m ERROR 12-22 23:26:34 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:26:36 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:26:36 [model.py:1750] Using max model len 5000
INFO 12-22 23:26:36 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:26:36 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:26:36 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:26:36 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=359259)[0;0m INFO 12-22 23:26:37 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=359259)[0;0m INFO 12-22 23:26:38 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:60979 backend=nccl
[0;36m(EngineCore_DP0 pid=359259)[0;0m INFO 12-22 23:26:38 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=359259)[0;0m INFO 12-22 23:26:39 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=359259)[0;0m INFO 12-22 23:26:39 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=359259)[0;0m INFO 12-22 23:26:40 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359259)[0;0m ERROR 12-22 23:26:40 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:26:42 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:26:42 [model.py:1750] Using max model len 5000
INFO 12-22 23:26:42 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:26:42 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:26:42 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:26:42 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=359321)[0;0m INFO 12-22 23:26:43 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=359321)[0;0m INFO 12-22 23:26:44 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:42453 backend=nccl
[0;36m(EngineCore_DP0 pid=359321)[0;0m INFO 12-22 23:26:44 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=359321)[0;0m INFO 12-22 23:26:45 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=359321)[0;0m INFO 12-22 23:26:45 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=359321)[0;0m INFO 12-22 23:26:46 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359321)[0;0m ERROR 12-22 23:26:47 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:26:48 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:26:48 [model.py:1750] Using max model len 5000
INFO 12-22 23:26:48 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:26:48 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:26:48 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:26:48 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=359383)[0;0m INFO 12-22 23:26:49 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=359383)[0;0m INFO 12-22 23:26:50 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:51059 backend=nccl
[0;36m(EngineCore_DP0 pid=359383)[0;0m INFO 12-22 23:26:50 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=359383)[0;0m INFO 12-22 23:26:51 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=359383)[0;0m INFO 12-22 23:26:51 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=359383)[0;0m INFO 12-22 23:26:52 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359383)[0;0m ERROR 12-22 23:26:53 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:26:54 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:26:54 [model.py:1750] Using max model len 5000
INFO 12-22 23:26:54 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:26:54 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:26:54 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:26:54 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=359445)[0;0m INFO 12-22 23:26:55 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=359445)[0;0m INFO 12-22 23:26:56 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:45955 backend=nccl
[0;36m(EngineCore_DP0 pid=359445)[0;0m INFO 12-22 23:26:56 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=359445)[0;0m INFO 12-22 23:26:57 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=359445)[0;0m INFO 12-22 23:26:57 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=359445)[0;0m INFO 12-22 23:26:58 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359445)[0;0m ERROR 12-22 23:26:59 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:27:00 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:27:00 [model.py:1750] Using max model len 5000
INFO 12-22 23:27:00 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:27:00 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:27:00 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:27:00 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=359850)[0;0m INFO 12-22 23:27:01 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=359850)[0;0m INFO 12-22 23:27:03 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:33705 backend=nccl
[0;36m(EngineCore_DP0 pid=359850)[0;0m INFO 12-22 23:27:03 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=359850)[0;0m INFO 12-22 23:27:04 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=359850)[0;0m INFO 12-22 23:27:04 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=359850)[0;0m INFO 12-22 23:27:05 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359850)[0;0m ERROR 12-22 23:27:05 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:27:07 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:27:07 [model.py:1750] Using max model len 5000
INFO 12-22 23:27:07 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:27:07 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:27:07 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:27:07 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=359912)[0;0m INFO 12-22 23:27:08 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=359912)[0;0m INFO 12-22 23:27:09 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:59419 backend=nccl
[0;36m(EngineCore_DP0 pid=359912)[0;0m INFO 12-22 23:27:09 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=359912)[0;0m INFO 12-22 23:27:10 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=359912)[0;0m INFO 12-22 23:27:10 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=359912)[0;0m INFO 12-22 23:27:11 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359912)[0;0m ERROR 12-22 23:27:11 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:27:14 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:27:14 [model.py:1750] Using max model len 5000
INFO 12-22 23:27:14 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:27:14 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:27:14 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:27:14 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=359974)[0;0m INFO 12-22 23:27:15 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=359974)[0;0m INFO 12-22 23:27:17 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:36655 backend=nccl
[0;36m(EngineCore_DP0 pid=359974)[0;0m INFO 12-22 23:27:17 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=359974)[0;0m INFO 12-22 23:27:17 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=359974)[0;0m INFO 12-22 23:27:18 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=359974)[0;0m INFO 12-22 23:27:18 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=359974)[0;0m ERROR 12-22 23:27:19 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:27:23 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:27:23 [model.py:1750] Using max model len 5000
INFO 12-22 23:27:23 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:27:23 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:27:23 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:27:23 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=360036)[0;0m INFO 12-22 23:27:23 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=360036)[0;0m INFO 12-22 23:27:25 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:44077 backend=nccl
[0;36m(EngineCore_DP0 pid=360036)[0;0m INFO 12-22 23:27:25 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=360036)[0;0m INFO 12-22 23:27:26 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=360036)[0;0m INFO 12-22 23:27:26 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=360036)[0;0m INFO 12-22 23:27:27 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360036)[0;0m ERROR 12-22 23:27:27 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:27:33 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:27:33 [model.py:1750] Using max model len 5000
INFO 12-22 23:27:33 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:27:33 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:27:33 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:27:33 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=360098)[0;0m INFO 12-22 23:27:36 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=360098)[0;0m INFO 12-22 23:27:38 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:35367 backend=nccl
[0;36m(EngineCore_DP0 pid=360098)[0;0m INFO 12-22 23:27:38 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=360098)[0;0m INFO 12-22 23:27:38 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=360098)[0;0m INFO 12-22 23:27:39 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=360098)[0;0m INFO 12-22 23:27:39 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360098)[0;0m ERROR 12-22 23:27:40 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:27:46 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:27:46 [model.py:1750] Using max model len 5000
INFO 12-22 23:27:46 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:27:46 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:27:46 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:27:46 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=360160)[0;0m INFO 12-22 23:27:48 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=360160)[0;0m INFO 12-22 23:27:49 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:45959 backend=nccl
[0;36m(EngineCore_DP0 pid=360160)[0;0m INFO 12-22 23:27:49 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=360160)[0;0m INFO 12-22 23:27:50 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=360160)[0;0m INFO 12-22 23:27:50 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=360160)[0;0m INFO 12-22 23:27:51 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360160)[0;0m ERROR 12-22 23:27:52 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:27:54 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:27:54 [model.py:1750] Using max model len 5000
INFO 12-22 23:27:54 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:27:54 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:27:54 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:27:54 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=360223)[0;0m INFO 12-22 23:27:54 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=360223)[0;0m INFO 12-22 23:27:56 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:50305 backend=nccl
[0;36m(EngineCore_DP0 pid=360223)[0;0m INFO 12-22 23:27:56 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=360223)[0;0m INFO 12-22 23:27:57 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=360223)[0;0m INFO 12-22 23:27:57 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=360223)[0;0m INFO 12-22 23:27:58 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360223)[0;0m ERROR 12-22 23:27:58 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:28:00 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:28:00 [model.py:1750] Using max model len 5000
INFO 12-22 23:28:00 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:28:00 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:28:00 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:28:00 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=360628)[0;0m INFO 12-22 23:28:01 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=360628)[0;0m INFO 12-22 23:28:03 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:35359 backend=nccl
[0;36m(EngineCore_DP0 pid=360628)[0;0m INFO 12-22 23:28:03 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=360628)[0;0m INFO 12-22 23:28:04 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=360628)[0;0m INFO 12-22 23:28:04 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=360628)[0;0m INFO 12-22 23:28:05 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360628)[0;0m ERROR 12-22 23:28:05 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:28:07 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:28:07 [model.py:1750] Using max model len 5000
INFO 12-22 23:28:07 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:28:07 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:28:07 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:28:07 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=360690)[0;0m INFO 12-22 23:28:08 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=360690)[0;0m INFO 12-22 23:28:09 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:46419 backend=nccl
[0;36m(EngineCore_DP0 pid=360690)[0;0m INFO 12-22 23:28:09 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=360690)[0;0m INFO 12-22 23:28:10 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=360690)[0;0m INFO 12-22 23:28:10 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=360690)[0;0m INFO 12-22 23:28:11 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360690)[0;0m ERROR 12-22 23:28:12 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:28:16 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:28:16 [model.py:1750] Using max model len 5000
INFO 12-22 23:28:16 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:28:16 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:28:16 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:28:16 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=360752)[0;0m INFO 12-22 23:28:23 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=360752)[0;0m INFO 12-22 23:28:25 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:39531 backend=nccl
[0;36m(EngineCore_DP0 pid=360752)[0;0m INFO 12-22 23:28:25 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=360752)[0;0m INFO 12-22 23:28:26 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=360752)[0;0m INFO 12-22 23:28:26 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=360752)[0;0m INFO 12-22 23:28:27 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360752)[0;0m ERROR 12-22 23:28:28 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:28:34 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:28:34 [model.py:1750] Using max model len 5000
INFO 12-22 23:28:34 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:28:34 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:28:34 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:28:34 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=360814)[0;0m INFO 12-22 23:28:39 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=360814)[0;0m INFO 12-22 23:28:41 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:44437 backend=nccl
[0;36m(EngineCore_DP0 pid=360814)[0;0m INFO 12-22 23:28:41 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=360814)[0;0m INFO 12-22 23:28:41 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=360814)[0;0m INFO 12-22 23:28:41 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=360814)[0;0m INFO 12-22 23:28:42 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360814)[0;0m ERROR 12-22 23:28:43 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:28:47 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:28:47 [model.py:1750] Using max model len 5000
INFO 12-22 23:28:47 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:28:47 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:28:47 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:28:47 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=360876)[0;0m INFO 12-22 23:28:50 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=360876)[0;0m INFO 12-22 23:28:52 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:53103 backend=nccl
[0;36m(EngineCore_DP0 pid=360876)[0;0m INFO 12-22 23:28:52 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=360876)[0;0m INFO 12-22 23:28:52 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=360876)[0;0m INFO 12-22 23:28:53 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=360876)[0;0m INFO 12-22 23:28:54 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=360876)[0;0m ERROR 12-22 23:28:54 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:29:00 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:29:00 [model.py:1750] Using max model len 5000
INFO 12-22 23:29:00 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:29:00 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:29:00 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:29:00 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=361281)[0;0m INFO 12-22 23:29:01 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=361281)[0;0m INFO 12-22 23:29:03 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:43971 backend=nccl
[0;36m(EngineCore_DP0 pid=361281)[0;0m INFO 12-22 23:29:03 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=361281)[0;0m INFO 12-22 23:29:03 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=361281)[0;0m INFO 12-22 23:29:04 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=361281)[0;0m INFO 12-22 23:29:04 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=361281)[0;0m ERROR 12-22 23:29:05 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:29:08 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:29:08 [model.py:1750] Using max model len 5000
INFO 12-22 23:29:08 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:29:08 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:29:08 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:29:08 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=361343)[0;0m INFO 12-22 23:29:11 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=361343)[0;0m INFO 12-22 23:29:13 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:39385 backend=nccl
[0;36m(EngineCore_DP0 pid=361343)[0;0m INFO 12-22 23:29:13 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=361343)[0;0m INFO 12-22 23:29:14 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=361343)[0;0m INFO 12-22 23:29:14 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=361343)[0;0m INFO 12-22 23:29:15 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=361343)[0;0m ERROR 12-22 23:29:15 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:29:17 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:29:17 [model.py:1750] Using max model len 5000
INFO 12-22 23:29:17 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:29:17 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:29:17 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:29:17 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=361405)[0;0m INFO 12-22 23:29:20 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=361405)[0;0m INFO 12-22 23:29:22 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:34683 backend=nccl
[0;36m(EngineCore_DP0 pid=361405)[0;0m INFO 12-22 23:29:22 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=361405)[0;0m INFO 12-22 23:29:22 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=361405)[0;0m INFO 12-22 23:29:23 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=361405)[0;0m INFO 12-22 23:29:23 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=361405)[0;0m ERROR 12-22 23:29:24 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:29:35 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:29:35 [model.py:1750] Using max model len 5000
INFO 12-22 23:29:35 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:29:35 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:29:35 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:29:35 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=361467)[0;0m INFO 12-22 23:29:36 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=361467)[0;0m INFO 12-22 23:29:38 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:33309 backend=nccl
[0;36m(EngineCore_DP0 pid=361467)[0;0m INFO 12-22 23:29:38 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=361467)[0;0m INFO 12-22 23:29:39 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=361467)[0;0m INFO 12-22 23:29:39 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=361467)[0;0m INFO 12-22 23:29:40 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=361467)[0;0m ERROR 12-22 23:29:41 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:29:43 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:29:43 [model.py:1750] Using max model len 5000
INFO 12-22 23:29:43 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:29:43 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:29:43 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:29:43 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=361529)[0;0m INFO 12-22 23:29:46 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=361529)[0;0m INFO 12-22 23:29:48 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:49829 backend=nccl
[0;36m(EngineCore_DP0 pid=361529)[0;0m INFO 12-22 23:29:48 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=361529)[0;0m INFO 12-22 23:29:49 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=361529)[0;0m INFO 12-22 23:29:49 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=361529)[0;0m INFO 12-22 23:29:50 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=361529)[0;0m ERROR 12-22 23:29:50 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:30:00 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:30:00 [model.py:1750] Using max model len 5000
INFO 12-22 23:30:00 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:30:00 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:30:00 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:30:00 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=361960)[0;0m INFO 12-22 23:30:02 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=361960)[0;0m INFO 12-22 23:30:04 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:59925 backend=nccl
[0;36m(EngineCore_DP0 pid=361960)[0;0m INFO 12-22 23:30:04 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=361960)[0;0m INFO 12-22 23:30:05 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=361960)[0;0m INFO 12-22 23:30:05 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=361960)[0;0m INFO 12-22 23:30:06 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=361960)[0;0m ERROR 12-22 23:30:06 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:30:11 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:30:11 [model.py:1750] Using max model len 5000
INFO 12-22 23:30:11 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:30:11 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:30:11 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:30:11 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=362022)[0;0m INFO 12-22 23:30:12 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=362022)[0;0m INFO 12-22 23:30:14 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:33165 backend=nccl
[0;36m(EngineCore_DP0 pid=362022)[0;0m INFO 12-22 23:30:14 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=362022)[0;0m INFO 12-22 23:30:14 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=362022)[0;0m INFO 12-22 23:30:14 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=362022)[0;0m INFO 12-22 23:30:15 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362022)[0;0m ERROR 12-22 23:30:16 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:30:17 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:30:17 [model.py:1750] Using max model len 5000
INFO 12-22 23:30:17 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:30:17 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:30:17 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:30:17 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=362084)[0;0m INFO 12-22 23:30:18 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=362084)[0;0m INFO 12-22 23:30:20 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:53623 backend=nccl
[0;36m(EngineCore_DP0 pid=362084)[0;0m INFO 12-22 23:30:20 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=362084)[0;0m INFO 12-22 23:30:20 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=362084)[0;0m INFO 12-22 23:30:21 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=362084)[0;0m INFO 12-22 23:30:22 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362084)[0;0m ERROR 12-22 23:30:22 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:30:25 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:30:25 [model.py:1750] Using max model len 5000
INFO 12-22 23:30:25 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:30:25 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:30:25 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:30:25 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=362146)[0;0m INFO 12-22 23:30:28 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=362146)[0;0m INFO 12-22 23:30:29 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:56339 backend=nccl
[0;36m(EngineCore_DP0 pid=362146)[0;0m INFO 12-22 23:30:29 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=362146)[0;0m INFO 12-22 23:30:30 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=362146)[0;0m INFO 12-22 23:30:30 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=362146)[0;0m INFO 12-22 23:30:31 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362146)[0;0m ERROR 12-22 23:30:32 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:30:34 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:30:34 [model.py:1750] Using max model len 5000
INFO 12-22 23:30:34 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:30:34 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:30:34 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:30:34 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=362208)[0;0m INFO 12-22 23:30:37 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=362208)[0;0m INFO 12-22 23:30:39 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:54065 backend=nccl
[0;36m(EngineCore_DP0 pid=362208)[0;0m INFO 12-22 23:30:39 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=362208)[0;0m INFO 12-22 23:30:40 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=362208)[0;0m INFO 12-22 23:30:40 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=362208)[0;0m INFO 12-22 23:30:41 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362208)[0;0m ERROR 12-22 23:30:41 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:30:43 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:30:43 [model.py:1750] Using max model len 5000
INFO 12-22 23:30:43 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:30:43 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:30:43 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:30:43 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=362270)[0;0m INFO 12-22 23:30:44 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=362270)[0;0m INFO 12-22 23:30:45 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:48703 backend=nccl
[0;36m(EngineCore_DP0 pid=362270)[0;0m INFO 12-22 23:30:45 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=362270)[0;0m INFO 12-22 23:30:46 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=362270)[0;0m INFO 12-22 23:30:46 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=362270)[0;0m INFO 12-22 23:30:47 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362270)[0;0m ERROR 12-22 23:30:48 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:30:49 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:30:49 [model.py:1750] Using max model len 5000
INFO 12-22 23:30:49 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:30:49 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:30:49 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:30:49 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=362332)[0;0m INFO 12-22 23:30:50 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=362332)[0;0m INFO 12-22 23:30:52 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:45433 backend=nccl
[0;36m(EngineCore_DP0 pid=362332)[0;0m INFO 12-22 23:30:52 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=362332)[0;0m INFO 12-22 23:30:53 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=362332)[0;0m INFO 12-22 23:30:53 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=362332)[0;0m INFO 12-22 23:30:54 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362332)[0;0m ERROR 12-22 23:30:55 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:30:56 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:30:56 [model.py:1750] Using max model len 5000
INFO 12-22 23:30:56 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:30:56 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:30:56 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:30:56 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=362738)[0;0m INFO 12-22 23:31:05 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=362738)[0;0m INFO 12-22 23:31:07 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:55483 backend=nccl
[0;36m(EngineCore_DP0 pid=362738)[0;0m INFO 12-22 23:31:07 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=362738)[0;0m INFO 12-22 23:31:08 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=362738)[0;0m INFO 12-22 23:31:08 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=362738)[0;0m INFO 12-22 23:31:09 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362738)[0;0m ERROR 12-22 23:31:10 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:31:11 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:31:11 [model.py:1750] Using max model len 5000
INFO 12-22 23:31:11 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:31:11 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:31:11 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:31:11 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=362801)[0;0m INFO 12-22 23:31:12 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=362801)[0;0m INFO 12-22 23:31:13 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:60517 backend=nccl
[0;36m(EngineCore_DP0 pid=362801)[0;0m INFO 12-22 23:31:13 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=362801)[0;0m INFO 12-22 23:31:14 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=362801)[0;0m INFO 12-22 23:31:14 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=362801)[0;0m INFO 12-22 23:31:15 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362801)[0;0m ERROR 12-22 23:31:16 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:31:18 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:31:18 [model.py:1750] Using max model len 5000
INFO 12-22 23:31:18 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:31:18 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:31:18 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:31:18 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=362863)[0;0m INFO 12-22 23:31:19 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=362863)[0;0m INFO 12-22 23:31:21 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:56031 backend=nccl
[0;36m(EngineCore_DP0 pid=362863)[0;0m INFO 12-22 23:31:21 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=362863)[0;0m INFO 12-22 23:31:22 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=362863)[0;0m INFO 12-22 23:31:22 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=362863)[0;0m INFO 12-22 23:31:23 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362863)[0;0m ERROR 12-22 23:31:24 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:31:25 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:31:25 [model.py:1750] Using max model len 5000
INFO 12-22 23:31:25 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:31:25 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:31:25 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:31:25 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=362925)[0;0m INFO 12-22 23:31:26 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=362925)[0;0m INFO 12-22 23:31:27 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:38649 backend=nccl
[0;36m(EngineCore_DP0 pid=362925)[0;0m INFO 12-22 23:31:27 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=362925)[0;0m INFO 12-22 23:31:28 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=362925)[0;0m INFO 12-22 23:31:28 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=362925)[0;0m INFO 12-22 23:31:29 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362925)[0;0m ERROR 12-22 23:31:30 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:31:31 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:31:31 [model.py:1750] Using max model len 5000
INFO 12-22 23:31:31 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:31:31 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:31:31 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:31:31 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=362987)[0;0m INFO 12-22 23:31:32 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=362987)[0;0m INFO 12-22 23:31:34 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:44979 backend=nccl
[0;36m(EngineCore_DP0 pid=362987)[0;0m INFO 12-22 23:31:34 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=362987)[0;0m INFO 12-22 23:31:35 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=362987)[0;0m INFO 12-22 23:31:35 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=362987)[0;0m INFO 12-22 23:31:36 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=362987)[0;0m ERROR 12-22 23:31:36 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:31:38 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:31:38 [model.py:1750] Using max model len 5000
INFO 12-22 23:31:38 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:31:38 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:31:38 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:31:38 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=363049)[0;0m INFO 12-22 23:31:39 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=363049)[0;0m INFO 12-22 23:31:41 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:53525 backend=nccl
[0;36m(EngineCore_DP0 pid=363049)[0;0m INFO 12-22 23:31:41 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=363049)[0;0m INFO 12-22 23:31:41 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=363049)[0;0m INFO 12-22 23:31:42 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=363049)[0;0m INFO 12-22 23:31:42 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363049)[0;0m ERROR 12-22 23:31:43 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:31:45 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:31:45 [model.py:1750] Using max model len 5000
INFO 12-22 23:31:45 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:31:45 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:31:45 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:31:45 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=363111)[0;0m INFO 12-22 23:31:46 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=363111)[0;0m INFO 12-22 23:31:50 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:52665 backend=nccl
[0;36m(EngineCore_DP0 pid=363111)[0;0m INFO 12-22 23:31:50 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=363111)[0;0m INFO 12-22 23:31:51 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=363111)[0;0m INFO 12-22 23:31:51 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=363111)[0;0m INFO 12-22 23:31:52 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363111)[0;0m ERROR 12-22 23:31:53 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:31:55 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:31:55 [model.py:1750] Using max model len 5000
INFO 12-22 23:31:55 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:31:55 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:31:55 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:31:55 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=363176)[0;0m INFO 12-22 23:31:56 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=363176)[0;0m INFO 12-22 23:31:57 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:53785 backend=nccl
[0;36m(EngineCore_DP0 pid=363176)[0;0m INFO 12-22 23:31:57 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=363176)[0;0m INFO 12-22 23:31:58 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=363176)[0;0m INFO 12-22 23:31:58 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=363176)[0;0m INFO 12-22 23:31:59 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363176)[0;0m ERROR 12-22 23:32:00 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:32:02 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:32:02 [model.py:1750] Using max model len 5000
INFO 12-22 23:32:02 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:32:02 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:32:02 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:32:02 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=363581)[0;0m INFO 12-22 23:32:04 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=363581)[0;0m INFO 12-22 23:32:06 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:50657 backend=nccl
[0;36m(EngineCore_DP0 pid=363581)[0;0m INFO 12-22 23:32:06 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=363581)[0;0m INFO 12-22 23:32:06 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=363581)[0;0m INFO 12-22 23:32:07 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=363581)[0;0m INFO 12-22 23:32:07 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363581)[0;0m ERROR 12-22 23:32:08 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:32:13 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:32:13 [model.py:1750] Using max model len 5000
INFO 12-22 23:32:13 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:32:13 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:32:13 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:32:13 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=363643)[0;0m INFO 12-22 23:32:15 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=363643)[0;0m INFO 12-22 23:32:16 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:39141 backend=nccl
[0;36m(EngineCore_DP0 pid=363643)[0;0m INFO 12-22 23:32:16 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=363643)[0;0m INFO 12-22 23:32:17 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=363643)[0;0m INFO 12-22 23:32:17 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=363643)[0;0m INFO 12-22 23:32:18 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363643)[0;0m ERROR 12-22 23:32:19 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:32:21 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:32:21 [model.py:1750] Using max model len 5000
INFO 12-22 23:32:21 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:32:21 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:32:21 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:32:21 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=363705)[0;0m INFO 12-22 23:32:24 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=363705)[0;0m INFO 12-22 23:32:26 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:46515 backend=nccl
[0;36m(EngineCore_DP0 pid=363705)[0;0m INFO 12-22 23:32:26 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=363705)[0;0m INFO 12-22 23:32:27 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=363705)[0;0m INFO 12-22 23:32:27 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=363705)[0;0m INFO 12-22 23:32:28 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363705)[0;0m ERROR 12-22 23:32:28 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:32:31 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:32:31 [model.py:1750] Using max model len 5000
INFO 12-22 23:32:31 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:32:31 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:32:31 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:32:31 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=363767)[0;0m INFO 12-22 23:32:32 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=363767)[0;0m INFO 12-22 23:32:34 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:49997 backend=nccl
[0;36m(EngineCore_DP0 pid=363767)[0;0m INFO 12-22 23:32:34 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=363767)[0;0m INFO 12-22 23:32:35 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=363767)[0;0m INFO 12-22 23:32:35 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=363767)[0;0m INFO 12-22 23:32:36 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363767)[0;0m ERROR 12-22 23:32:36 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:32:41 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:32:41 [model.py:1750] Using max model len 5000
INFO 12-22 23:32:41 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:32:41 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:32:41 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:32:41 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=363829)[0;0m INFO 12-22 23:32:43 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=363829)[0;0m INFO 12-22 23:32:45 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:41521 backend=nccl
[0;36m(EngineCore_DP0 pid=363829)[0;0m INFO 12-22 23:32:45 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=363829)[0;0m INFO 12-22 23:32:45 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=363829)[0;0m INFO 12-22 23:32:46 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=363829)[0;0m INFO 12-22 23:32:46 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363829)[0;0m ERROR 12-22 23:32:47 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:32:50 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:32:50 [model.py:1750] Using max model len 5000
INFO 12-22 23:32:50 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:32:50 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:32:50 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:32:50 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=363891)[0;0m INFO 12-22 23:32:51 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=363891)[0;0m INFO 12-22 23:32:53 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:39695 backend=nccl
[0;36m(EngineCore_DP0 pid=363891)[0;0m INFO 12-22 23:32:53 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=363891)[0;0m INFO 12-22 23:32:54 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=363891)[0;0m INFO 12-22 23:32:54 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=363891)[0;0m INFO 12-22 23:32:55 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=363891)[0;0m ERROR 12-22 23:32:56 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:32:58 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:32:58 [model.py:1750] Using max model len 5000
INFO 12-22 23:32:58 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:32:58 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:32:58 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:32:58 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=364292)[0;0m INFO 12-22 23:33:00 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=364292)[0;0m INFO 12-22 23:33:01 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:44597 backend=nccl
[0;36m(EngineCore_DP0 pid=364292)[0;0m INFO 12-22 23:33:01 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=364292)[0;0m INFO 12-22 23:33:02 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=364292)[0;0m INFO 12-22 23:33:02 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=364292)[0;0m INFO 12-22 23:33:03 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364292)[0;0m ERROR 12-22 23:33:04 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:33:06 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:33:06 [model.py:1750] Using max model len 5000
INFO 12-22 23:33:06 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:33:06 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:33:06 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:33:06 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=364358)[0;0m INFO 12-22 23:33:08 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=364358)[0;0m INFO 12-22 23:33:09 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:56709 backend=nccl
[0;36m(EngineCore_DP0 pid=364358)[0;0m INFO 12-22 23:33:09 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=364358)[0;0m INFO 12-22 23:33:10 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=364358)[0;0m INFO 12-22 23:33:10 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=364358)[0;0m INFO 12-22 23:33:11 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364358)[0;0m ERROR 12-22 23:33:12 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:33:17 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:33:17 [model.py:1750] Using max model len 5000
INFO 12-22 23:33:17 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:33:17 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:33:17 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:33:17 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=364421)[0;0m INFO 12-22 23:33:19 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=364421)[0;0m INFO 12-22 23:33:20 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:51243 backend=nccl
[0;36m(EngineCore_DP0 pid=364421)[0;0m INFO 12-22 23:33:20 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=364421)[0;0m INFO 12-22 23:33:21 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=364421)[0;0m INFO 12-22 23:33:21 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=364421)[0;0m INFO 12-22 23:33:22 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364421)[0;0m ERROR 12-22 23:33:22 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:33:25 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:33:25 [model.py:1750] Using max model len 5000
INFO 12-22 23:33:25 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:33:25 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:33:25 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:33:25 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=364483)[0;0m INFO 12-22 23:33:28 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=364483)[0;0m INFO 12-22 23:33:30 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:53425 backend=nccl
[0;36m(EngineCore_DP0 pid=364483)[0;0m INFO 12-22 23:33:30 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=364483)[0;0m INFO 12-22 23:33:31 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=364483)[0;0m INFO 12-22 23:33:31 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=364483)[0;0m INFO 12-22 23:33:32 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364483)[0;0m ERROR 12-22 23:33:32 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:33:35 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:33:35 [model.py:1750] Using max model len 5000
INFO 12-22 23:33:35 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:33:35 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:33:35 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:33:35 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=364545)[0;0m INFO 12-22 23:33:37 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=364545)[0;0m INFO 12-22 23:33:38 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:32983 backend=nccl
[0;36m(EngineCore_DP0 pid=364545)[0;0m INFO 12-22 23:33:38 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=364545)[0;0m INFO 12-22 23:33:39 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=364545)[0;0m INFO 12-22 23:33:39 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=364545)[0;0m INFO 12-22 23:33:40 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364545)[0;0m ERROR 12-22 23:33:41 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:33:42 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:33:42 [model.py:1750] Using max model len 5000
INFO 12-22 23:33:42 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:33:42 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:33:42 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:33:42 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=364607)[0;0m INFO 12-22 23:33:44 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=364607)[0;0m INFO 12-22 23:33:45 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:34337 backend=nccl
[0;36m(EngineCore_DP0 pid=364607)[0;0m INFO 12-22 23:33:45 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=364607)[0;0m INFO 12-22 23:33:46 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=364607)[0;0m INFO 12-22 23:33:46 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=364607)[0;0m INFO 12-22 23:33:47 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364607)[0;0m ERROR 12-22 23:33:48 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:33:50 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:33:50 [model.py:1750] Using max model len 5000
INFO 12-22 23:33:50 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:33:50 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:33:50 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:33:50 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=364669)[0;0m INFO 12-22 23:33:52 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=364669)[0;0m INFO 12-22 23:33:53 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:36387 backend=nccl
[0;36m(EngineCore_DP0 pid=364669)[0;0m INFO 12-22 23:33:54 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=364669)[0;0m INFO 12-22 23:33:54 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=364669)[0;0m INFO 12-22 23:33:54 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=364669)[0;0m INFO 12-22 23:33:55 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364669)[0;0m ERROR 12-22 23:33:56 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:33:57 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:33:57 [model.py:1750] Using max model len 5000
INFO 12-22 23:33:57 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:33:57 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:33:57 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:33:57 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=364731)[0;0m INFO 12-22 23:33:58 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=364731)[0;0m INFO 12-22 23:33:59 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:42475 backend=nccl
[0;36m(EngineCore_DP0 pid=364731)[0;0m INFO 12-22 23:33:59 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=364731)[0;0m INFO 12-22 23:34:00 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=364731)[0;0m INFO 12-22 23:34:00 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=364731)[0;0m INFO 12-22 23:34:01 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=364731)[0;0m ERROR 12-22 23:34:01 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:34:03 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:34:03 [model.py:1750] Using max model len 5000
INFO 12-22 23:34:03 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:34:03 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:34:03 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:34:03 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=365136)[0;0m INFO 12-22 23:34:03 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=365136)[0;0m INFO 12-22 23:34:05 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:36419 backend=nccl
[0;36m(EngineCore_DP0 pid=365136)[0;0m INFO 12-22 23:34:05 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=365136)[0;0m INFO 12-22 23:34:05 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=365136)[0;0m INFO 12-22 23:34:06 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=365136)[0;0m INFO 12-22 23:34:06 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365136)[0;0m ERROR 12-22 23:34:07 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:34:09 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:34:09 [model.py:1750] Using max model len 5000
INFO 12-22 23:34:09 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:34:09 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:34:09 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:34:09 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=365199)[0;0m INFO 12-22 23:34:11 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=365199)[0;0m INFO 12-22 23:34:13 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:59701 backend=nccl
[0;36m(EngineCore_DP0 pid=365199)[0;0m INFO 12-22 23:34:13 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=365199)[0;0m INFO 12-22 23:34:13 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=365199)[0;0m INFO 12-22 23:34:14 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=365199)[0;0m INFO 12-22 23:34:14 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365199)[0;0m ERROR 12-22 23:34:15 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:34:19 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:34:19 [model.py:1750] Using max model len 5000
INFO 12-22 23:34:19 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:34:19 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:34:19 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:34:19 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=365261)[0;0m INFO 12-22 23:34:19 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=365261)[0;0m INFO 12-22 23:34:21 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:48123 backend=nccl
[0;36m(EngineCore_DP0 pid=365261)[0;0m INFO 12-22 23:34:21 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=365261)[0;0m INFO 12-22 23:34:22 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=365261)[0;0m INFO 12-22 23:34:22 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=365261)[0;0m INFO 12-22 23:34:23 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365261)[0;0m ERROR 12-22 23:34:23 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:34:24 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:34:24 [model.py:1750] Using max model len 5000
INFO 12-22 23:34:24 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:34:24 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:34:24 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:34:24 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=365323)[0;0m INFO 12-22 23:34:25 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=365323)[0;0m INFO 12-22 23:34:27 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:59755 backend=nccl
[0;36m(EngineCore_DP0 pid=365323)[0;0m INFO 12-22 23:34:27 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=365323)[0;0m INFO 12-22 23:34:27 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=365323)[0;0m INFO 12-22 23:34:28 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=365323)[0;0m INFO 12-22 23:34:28 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365323)[0;0m ERROR 12-22 23:34:29 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:34:30 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:34:30 [model.py:1750] Using max model len 5000
INFO 12-22 23:34:30 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:34:30 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:34:30 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:34:30 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=365385)[0;0m INFO 12-22 23:34:31 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=365385)[0;0m INFO 12-22 23:34:32 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:57197 backend=nccl
[0;36m(EngineCore_DP0 pid=365385)[0;0m INFO 12-22 23:34:32 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=365385)[0;0m INFO 12-22 23:34:33 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=365385)[0;0m INFO 12-22 23:34:33 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=365385)[0;0m INFO 12-22 23:34:34 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365385)[0;0m ERROR 12-22 23:34:34 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:34:36 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:34:36 [model.py:1750] Using max model len 5000
INFO 12-22 23:34:36 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:34:36 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:34:36 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:34:36 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=365447)[0;0m INFO 12-22 23:34:36 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=365447)[0;0m INFO 12-22 23:34:38 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:41129 backend=nccl
[0;36m(EngineCore_DP0 pid=365447)[0;0m INFO 12-22 23:34:38 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=365447)[0;0m INFO 12-22 23:34:38 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=365447)[0;0m INFO 12-22 23:34:39 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=365447)[0;0m INFO 12-22 23:34:39 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365447)[0;0m ERROR 12-22 23:34:40 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:34:41 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:34:41 [model.py:1750] Using max model len 5000
INFO 12-22 23:34:41 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:34:41 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:34:41 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:34:41 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=365509)[0;0m INFO 12-22 23:34:42 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=365509)[0;0m INFO 12-22 23:34:43 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:40859 backend=nccl
[0;36m(EngineCore_DP0 pid=365509)[0;0m INFO 12-22 23:34:44 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=365509)[0;0m INFO 12-22 23:34:44 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=365509)[0;0m INFO 12-22 23:34:44 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=365509)[0;0m INFO 12-22 23:34:45 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365509)[0;0m ERROR 12-22 23:34:46 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:34:47 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:34:47 [model.py:1750] Using max model len 5000
INFO 12-22 23:34:47 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:34:47 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:34:47 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:34:47 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=365571)[0;0m INFO 12-22 23:34:47 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=365571)[0;0m INFO 12-22 23:34:49 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:51223 backend=nccl
[0;36m(EngineCore_DP0 pid=365571)[0;0m INFO 12-22 23:34:49 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=365571)[0;0m INFO 12-22 23:34:50 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=365571)[0;0m INFO 12-22 23:34:50 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=365571)[0;0m INFO 12-22 23:34:50 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365571)[0;0m ERROR 12-22 23:34:51 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:34:54 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:34:54 [model.py:1750] Using max model len 5000
INFO 12-22 23:34:54 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:34:54 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:34:54 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:34:54 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=365633)[0;0m INFO 12-22 23:34:56 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=365633)[0;0m INFO 12-22 23:34:57 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:47617 backend=nccl
[0;36m(EngineCore_DP0 pid=365633)[0;0m INFO 12-22 23:34:57 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=365633)[0;0m INFO 12-22 23:34:58 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=365633)[0;0m INFO 12-22 23:34:58 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=365633)[0;0m INFO 12-22 23:34:59 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=365633)[0;0m ERROR 12-22 23:35:00 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:35:02 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:35:02 [model.py:1750] Using max model len 5000
INFO 12-22 23:35:02 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:35:02 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:35:02 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:35:02 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=366041)[0;0m INFO 12-22 23:35:05 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=366041)[0;0m INFO 12-22 23:35:07 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:35127 backend=nccl
[0;36m(EngineCore_DP0 pid=366041)[0;0m INFO 12-22 23:35:07 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=366041)[0;0m INFO 12-22 23:35:07 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=366041)[0;0m INFO 12-22 23:35:08 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=366041)[0;0m INFO 12-22 23:35:08 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366041)[0;0m ERROR 12-22 23:35:09 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:35:12 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:35:12 [model.py:1750] Using max model len 5000
INFO 12-22 23:35:12 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:35:12 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:35:12 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:35:12 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=366103)[0;0m INFO 12-22 23:35:13 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=366103)[0;0m INFO 12-22 23:35:15 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:38511 backend=nccl
[0;36m(EngineCore_DP0 pid=366103)[0;0m INFO 12-22 23:35:15 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=366103)[0;0m INFO 12-22 23:35:15 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=366103)[0;0m INFO 12-22 23:35:15 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=366103)[0;0m INFO 12-22 23:35:16 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366103)[0;0m ERROR 12-22 23:35:17 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:35:19 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:35:19 [model.py:1750] Using max model len 5000
INFO 12-22 23:35:19 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:35:19 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:35:19 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:35:19 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=366165)[0;0m INFO 12-22 23:35:20 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=366165)[0;0m INFO 12-22 23:35:21 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:42457 backend=nccl
[0;36m(EngineCore_DP0 pid=366165)[0;0m INFO 12-22 23:35:22 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=366165)[0;0m INFO 12-22 23:35:22 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=366165)[0;0m INFO 12-22 23:35:22 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=366165)[0;0m INFO 12-22 23:35:23 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366165)[0;0m ERROR 12-22 23:35:24 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:35:25 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:35:25 [model.py:1750] Using max model len 5000
INFO 12-22 23:35:25 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:35:25 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:35:25 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:35:25 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=366227)[0;0m INFO 12-22 23:35:26 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=366227)[0;0m INFO 12-22 23:35:28 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:55579 backend=nccl
[0;36m(EngineCore_DP0 pid=366227)[0;0m INFO 12-22 23:35:28 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=366227)[0;0m INFO 12-22 23:35:28 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=366227)[0;0m INFO 12-22 23:35:29 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=366227)[0;0m INFO 12-22 23:35:29 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366227)[0;0m ERROR 12-22 23:35:30 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:35:33 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:35:33 [model.py:1750] Using max model len 5000
INFO 12-22 23:35:33 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:35:33 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:35:33 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:35:33 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=366289)[0;0m INFO 12-22 23:35:34 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=366289)[0;0m INFO 12-22 23:35:35 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:44603 backend=nccl
[0;36m(EngineCore_DP0 pid=366289)[0;0m INFO 12-22 23:35:35 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=366289)[0;0m INFO 12-22 23:35:36 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=366289)[0;0m INFO 12-22 23:35:36 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=366289)[0;0m INFO 12-22 23:35:37 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366289)[0;0m ERROR 12-22 23:35:38 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:35:41 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:35:41 [model.py:1750] Using max model len 5000
INFO 12-22 23:35:41 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:35:41 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:35:41 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:35:41 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=366351)[0;0m INFO 12-22 23:35:42 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=366351)[0;0m INFO 12-22 23:35:44 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:56497 backend=nccl
[0;36m(EngineCore_DP0 pid=366351)[0;0m INFO 12-22 23:35:44 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=366351)[0;0m INFO 12-22 23:35:45 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=366351)[0;0m INFO 12-22 23:35:45 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=366351)[0;0m INFO 12-22 23:35:46 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366351)[0;0m ERROR 12-22 23:35:47 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:35:49 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:35:49 [model.py:1750] Using max model len 5000
INFO 12-22 23:35:49 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:35:49 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:35:49 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:35:49 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=366413)[0;0m INFO 12-22 23:35:50 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=366413)[0;0m INFO 12-22 23:35:51 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:43807 backend=nccl
[0;36m(EngineCore_DP0 pid=366413)[0;0m INFO 12-22 23:35:51 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=366413)[0;0m INFO 12-22 23:35:52 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=366413)[0;0m INFO 12-22 23:35:52 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=366413)[0;0m INFO 12-22 23:35:53 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366413)[0;0m ERROR 12-22 23:35:54 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:35:55 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:35:55 [model.py:1750] Using max model len 5000
INFO 12-22 23:35:55 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:35:55 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:35:55 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:35:55 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=366475)[0;0m INFO 12-22 23:35:56 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=366475)[0;0m INFO 12-22 23:35:58 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:45399 backend=nccl
[0;36m(EngineCore_DP0 pid=366475)[0;0m INFO 12-22 23:35:58 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=366475)[0;0m INFO 12-22 23:35:58 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=366475)[0;0m INFO 12-22 23:35:59 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=366475)[0;0m INFO 12-22 23:35:59 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366475)[0;0m ERROR 12-22 23:36:00 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:36:01 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:36:01 [model.py:1750] Using max model len 5000
INFO 12-22 23:36:01 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:36:01 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:36:01 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:36:01 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=366880)[0;0m INFO 12-22 23:36:02 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=366880)[0;0m INFO 12-22 23:36:04 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:50967 backend=nccl
[0;36m(EngineCore_DP0 pid=366880)[0;0m INFO 12-22 23:36:04 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=366880)[0;0m INFO 12-22 23:36:05 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=366880)[0;0m INFO 12-22 23:36:05 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=366880)[0;0m INFO 12-22 23:36:06 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366880)[0;0m ERROR 12-22 23:36:06 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:36:08 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:36:08 [model.py:1750] Using max model len 5000
INFO 12-22 23:36:08 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:36:08 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:36:08 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:36:08 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=366942)[0;0m INFO 12-22 23:36:09 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=366942)[0;0m INFO 12-22 23:36:11 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:33107 backend=nccl
[0;36m(EngineCore_DP0 pid=366942)[0;0m INFO 12-22 23:36:11 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=366942)[0;0m INFO 12-22 23:36:11 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=366942)[0;0m INFO 12-22 23:36:12 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=366942)[0;0m INFO 12-22 23:36:13 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=366942)[0;0m ERROR 12-22 23:36:13 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:36:15 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:36:15 [model.py:1750] Using max model len 5000
INFO 12-22 23:36:15 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:36:15 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:36:15 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:36:15 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=367004)[0;0m INFO 12-22 23:36:16 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=367004)[0;0m INFO 12-22 23:36:18 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:46133 backend=nccl
[0;36m(EngineCore_DP0 pid=367004)[0;0m INFO 12-22 23:36:18 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=367004)[0;0m INFO 12-22 23:36:19 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=367004)[0;0m INFO 12-22 23:36:19 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=367004)[0;0m INFO 12-22 23:36:20 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367004)[0;0m ERROR 12-22 23:36:21 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:36:22 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:36:22 [model.py:1750] Using max model len 5000
INFO 12-22 23:36:22 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:36:22 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:36:22 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:36:22 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=367066)[0;0m INFO 12-22 23:36:23 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=367066)[0;0m INFO 12-22 23:36:25 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:50699 backend=nccl
[0;36m(EngineCore_DP0 pid=367066)[0;0m INFO 12-22 23:36:25 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=367066)[0;0m INFO 12-22 23:36:26 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=367066)[0;0m INFO 12-22 23:36:26 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=367066)[0;0m INFO 12-22 23:36:27 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367066)[0;0m ERROR 12-22 23:36:27 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:36:29 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:36:29 [model.py:1750] Using max model len 5000
INFO 12-22 23:36:29 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:36:29 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:36:29 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:36:29 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=367129)[0;0m INFO 12-22 23:36:30 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=367129)[0;0m INFO 12-22 23:36:32 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:43373 backend=nccl
[0;36m(EngineCore_DP0 pid=367129)[0;0m INFO 12-22 23:36:32 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=367129)[0;0m INFO 12-22 23:36:32 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=367129)[0;0m INFO 12-22 23:36:33 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=367129)[0;0m INFO 12-22 23:36:33 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367129)[0;0m ERROR 12-22 23:36:34 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:36:36 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:36:36 [model.py:1750] Using max model len 5000
INFO 12-22 23:36:36 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:36:36 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:36:36 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:36:36 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=367191)[0;0m INFO 12-22 23:36:38 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=367191)[0;0m INFO 12-22 23:36:39 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:36793 backend=nccl
[0;36m(EngineCore_DP0 pid=367191)[0;0m INFO 12-22 23:36:39 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=367191)[0;0m INFO 12-22 23:36:40 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=367191)[0;0m INFO 12-22 23:36:40 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=367191)[0;0m INFO 12-22 23:36:41 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367191)[0;0m ERROR 12-22 23:36:42 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:36:45 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:36:45 [model.py:1750] Using max model len 5000
INFO 12-22 23:36:45 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:36:45 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:36:45 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:36:45 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=367253)[0;0m INFO 12-22 23:36:46 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=367253)[0;0m INFO 12-22 23:36:48 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:46269 backend=nccl
[0;36m(EngineCore_DP0 pid=367253)[0;0m INFO 12-22 23:36:48 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=367253)[0;0m INFO 12-22 23:36:49 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=367253)[0;0m INFO 12-22 23:36:49 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=367253)[0;0m INFO 12-22 23:36:50 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367253)[0;0m ERROR 12-22 23:36:51 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:36:53 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:36:53 [model.py:1750] Using max model len 5000
INFO 12-22 23:36:53 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:36:53 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:36:53 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:36:53 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=367315)[0;0m INFO 12-22 23:36:55 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=367315)[0;0m INFO 12-22 23:36:56 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:58843 backend=nccl
[0;36m(EngineCore_DP0 pid=367315)[0;0m INFO 12-22 23:36:56 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=367315)[0;0m INFO 12-22 23:36:57 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=367315)[0;0m INFO 12-22 23:36:57 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=367315)[0;0m INFO 12-22 23:36:58 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367315)[0;0m ERROR 12-22 23:36:59 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:37:01 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:37:01 [model.py:1750] Using max model len 5000
INFO 12-22 23:37:01 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:37:01 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:37:01 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:37:01 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=367720)[0;0m INFO 12-22 23:37:03 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=367720)[0;0m INFO 12-22 23:37:04 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:56473 backend=nccl
[0;36m(EngineCore_DP0 pid=367720)[0;0m INFO 12-22 23:37:04 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=367720)[0;0m INFO 12-22 23:37:05 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=367720)[0;0m INFO 12-22 23:37:05 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=367720)[0;0m INFO 12-22 23:37:06 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367720)[0;0m ERROR 12-22 23:37:07 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:37:08 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:37:08 [model.py:1750] Using max model len 5000
INFO 12-22 23:37:08 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:37:08 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:37:08 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:37:08 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=367782)[0;0m INFO 12-22 23:37:09 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=367782)[0;0m INFO 12-22 23:37:12 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:35121 backend=nccl
[0;36m(EngineCore_DP0 pid=367782)[0;0m INFO 12-22 23:37:12 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=367782)[0;0m INFO 12-22 23:37:12 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=367782)[0;0m INFO 12-22 23:37:12 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=367782)[0;0m INFO 12-22 23:37:13 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367782)[0;0m ERROR 12-22 23:37:14 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:37:16 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:37:16 [model.py:1750] Using max model len 5000
INFO 12-22 23:37:16 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:37:16 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:37:16 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:37:16 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=367844)[0;0m INFO 12-22 23:37:16 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=367844)[0;0m INFO 12-22 23:37:18 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:45439 backend=nccl
[0;36m(EngineCore_DP0 pid=367844)[0;0m INFO 12-22 23:37:18 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=367844)[0;0m INFO 12-22 23:37:19 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=367844)[0;0m INFO 12-22 23:37:19 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=367844)[0;0m INFO 12-22 23:37:20 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367844)[0;0m ERROR 12-22 23:37:21 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:37:22 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:37:22 [model.py:1750] Using max model len 5000
INFO 12-22 23:37:22 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:37:22 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:37:22 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:37:22 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=367906)[0;0m INFO 12-22 23:37:24 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=367906)[0;0m INFO 12-22 23:37:26 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:54129 backend=nccl
[0;36m(EngineCore_DP0 pid=367906)[0;0m INFO 12-22 23:37:26 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=367906)[0;0m INFO 12-22 23:37:26 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=367906)[0;0m INFO 12-22 23:37:26 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=367906)[0;0m INFO 12-22 23:37:27 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367906)[0;0m ERROR 12-22 23:37:28 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:37:29 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:37:29 [model.py:1750] Using max model len 5000
INFO 12-22 23:37:29 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:37:29 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:37:29 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:37:29 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=367968)[0;0m INFO 12-22 23:37:31 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=367968)[0;0m INFO 12-22 23:37:33 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:42289 backend=nccl
[0;36m(EngineCore_DP0 pid=367968)[0;0m INFO 12-22 23:37:33 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=367968)[0;0m INFO 12-22 23:37:33 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=367968)[0;0m INFO 12-22 23:37:34 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=367968)[0;0m INFO 12-22 23:37:35 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=367968)[0;0m ERROR 12-22 23:37:35 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:37:39 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:37:39 [model.py:1750] Using max model len 5000
INFO 12-22 23:37:39 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:37:39 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:37:39 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:37:39 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=368030)[0;0m INFO 12-22 23:37:40 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=368030)[0;0m INFO 12-22 23:37:41 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:55313 backend=nccl
[0;36m(EngineCore_DP0 pid=368030)[0;0m INFO 12-22 23:37:41 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=368030)[0;0m INFO 12-22 23:37:42 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=368030)[0;0m INFO 12-22 23:37:42 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=368030)[0;0m INFO 12-22 23:37:43 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368030)[0;0m ERROR 12-22 23:37:44 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:37:45 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:37:45 [model.py:1750] Using max model len 5000
INFO 12-22 23:37:45 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:37:45 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:37:45 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:37:45 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=368092)[0;0m INFO 12-22 23:37:46 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=368092)[0;0m INFO 12-22 23:37:47 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:43145 backend=nccl
[0;36m(EngineCore_DP0 pid=368092)[0;0m INFO 12-22 23:37:48 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=368092)[0;0m INFO 12-22 23:37:48 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=368092)[0;0m INFO 12-22 23:37:48 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=368092)[0;0m INFO 12-22 23:37:49 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368092)[0;0m ERROR 12-22 23:37:50 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:37:51 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:37:51 [model.py:1750] Using max model len 5000
INFO 12-22 23:37:51 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:37:51 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:37:51 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:37:51 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=368154)[0;0m INFO 12-22 23:37:52 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=368154)[0;0m INFO 12-22 23:37:54 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:38151 backend=nccl
[0;36m(EngineCore_DP0 pid=368154)[0;0m INFO 12-22 23:37:54 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=368154)[0;0m INFO 12-22 23:37:55 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=368154)[0;0m INFO 12-22 23:37:55 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=368154)[0;0m INFO 12-22 23:37:56 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368154)[0;0m ERROR 12-22 23:37:56 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:37:58 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:37:58 [model.py:1750] Using max model len 5000
INFO 12-22 23:37:58 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:37:58 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:37:58 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:37:58 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=368216)[0;0m INFO 12-22 23:37:59 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=368216)[0;0m INFO 12-22 23:38:01 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:36315 backend=nccl
[0;36m(EngineCore_DP0 pid=368216)[0;0m INFO 12-22 23:38:01 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=368216)[0;0m INFO 12-22 23:38:01 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=368216)[0;0m INFO 12-22 23:38:02 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=368216)[0;0m INFO 12-22 23:38:02 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368216)[0;0m ERROR 12-22 23:38:03 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:38:04 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:38:04 [model.py:1750] Using max model len 5000
INFO 12-22 23:38:04 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:38:04 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:38:04 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:38:04 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=368621)[0;0m INFO 12-22 23:38:06 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=368621)[0;0m INFO 12-22 23:38:07 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:52383 backend=nccl
[0;36m(EngineCore_DP0 pid=368621)[0;0m INFO 12-22 23:38:07 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=368621)[0;0m INFO 12-22 23:38:08 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=368621)[0;0m INFO 12-22 23:38:08 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=368621)[0;0m INFO 12-22 23:38:09 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368621)[0;0m ERROR 12-22 23:38:09 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:38:11 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:38:11 [model.py:1750] Using max model len 5000
INFO 12-22 23:38:11 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:38:11 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:38:11 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:38:11 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=368683)[0;0m INFO 12-22 23:38:12 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=368683)[0;0m INFO 12-22 23:38:14 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:41267 backend=nccl
[0;36m(EngineCore_DP0 pid=368683)[0;0m INFO 12-22 23:38:14 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=368683)[0;0m INFO 12-22 23:38:14 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=368683)[0;0m INFO 12-22 23:38:15 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=368683)[0;0m INFO 12-22 23:38:16 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368683)[0;0m ERROR 12-22 23:38:16 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:38:18 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:38:18 [model.py:1750] Using max model len 5000
INFO 12-22 23:38:18 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:38:18 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:38:18 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:38:18 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=368746)[0;0m INFO 12-22 23:38:20 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=368746)[0;0m INFO 12-22 23:38:22 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:56369 backend=nccl
[0;36m(EngineCore_DP0 pid=368746)[0;0m INFO 12-22 23:38:22 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=368746)[0;0m INFO 12-22 23:38:22 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=368746)[0;0m INFO 12-22 23:38:23 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=368746)[0;0m INFO 12-22 23:38:24 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368746)[0;0m ERROR 12-22 23:38:24 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:38:27 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:38:27 [model.py:1750] Using max model len 5000
INFO 12-22 23:38:27 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:38:27 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:38:27 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:38:27 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=368808)[0;0m INFO 12-22 23:38:28 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=368808)[0;0m INFO 12-22 23:38:30 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:49775 backend=nccl
[0;36m(EngineCore_DP0 pid=368808)[0;0m INFO 12-22 23:38:30 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=368808)[0;0m INFO 12-22 23:38:31 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=368808)[0;0m INFO 12-22 23:38:31 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=368808)[0;0m INFO 12-22 23:38:32 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368808)[0;0m ERROR 12-22 23:38:32 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:38:35 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:38:35 [model.py:1750] Using max model len 5000
INFO 12-22 23:38:35 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:38:35 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:38:35 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:38:35 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=368870)[0;0m INFO 12-22 23:38:36 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=368870)[0;0m INFO 12-22 23:38:38 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:45519 backend=nccl
[0;36m(EngineCore_DP0 pid=368870)[0;0m INFO 12-22 23:38:38 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=368870)[0;0m INFO 12-22 23:38:38 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=368870)[0;0m INFO 12-22 23:38:38 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=368870)[0;0m INFO 12-22 23:38:39 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368870)[0;0m ERROR 12-22 23:38:40 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:38:42 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:38:42 [model.py:1750] Using max model len 5000
INFO 12-22 23:38:42 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:38:42 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:38:42 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:38:42 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=368932)[0;0m INFO 12-22 23:38:43 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=368932)[0;0m INFO 12-22 23:38:45 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:47885 backend=nccl
[0;36m(EngineCore_DP0 pid=368932)[0;0m INFO 12-22 23:38:45 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=368932)[0;0m INFO 12-22 23:38:46 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=368932)[0;0m INFO 12-22 23:38:46 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=368932)[0;0m INFO 12-22 23:38:47 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368932)[0;0m ERROR 12-22 23:38:47 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:38:51 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:38:51 [model.py:1750] Using max model len 5000
INFO 12-22 23:38:51 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:38:51 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:38:51 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:38:51 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=368994)[0;0m INFO 12-22 23:38:52 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=368994)[0;0m INFO 12-22 23:38:54 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:56745 backend=nccl
[0;36m(EngineCore_DP0 pid=368994)[0;0m INFO 12-22 23:38:54 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=368994)[0;0m INFO 12-22 23:38:55 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=368994)[0;0m INFO 12-22 23:38:55 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=368994)[0;0m INFO 12-22 23:38:56 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=368994)[0;0m ERROR 12-22 23:38:56 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:39:00 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:39:00 [model.py:1750] Using max model len 5000
INFO 12-22 23:39:00 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:39:00 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:39:00 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:39:00 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=369399)[0;0m INFO 12-22 23:39:02 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=369399)[0;0m INFO 12-22 23:39:04 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:49677 backend=nccl
[0;36m(EngineCore_DP0 pid=369399)[0;0m INFO 12-22 23:39:04 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=369399)[0;0m INFO 12-22 23:39:05 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=369399)[0;0m INFO 12-22 23:39:05 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=369399)[0;0m INFO 12-22 23:39:06 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=369399)[0;0m ERROR 12-22 23:39:06 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:39:08 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:39:08 [model.py:1750] Using max model len 5000
INFO 12-22 23:39:08 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:39:08 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:39:08 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:39:08 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=369461)[0;0m INFO 12-22 23:39:09 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=369461)[0;0m INFO 12-22 23:39:11 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:40953 backend=nccl
[0;36m(EngineCore_DP0 pid=369461)[0;0m INFO 12-22 23:39:11 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=369461)[0;0m INFO 12-22 23:39:11 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=369461)[0;0m INFO 12-22 23:39:12 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=369461)[0;0m INFO 12-22 23:39:13 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=369461)[0;0m ERROR 12-22 23:39:13 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:39:16 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:39:16 [model.py:1750] Using max model len 5000
INFO 12-22 23:39:16 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:39:16 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:39:16 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:39:16 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=369523)[0;0m INFO 12-22 23:39:17 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=369523)[0;0m INFO 12-22 23:39:18 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:60971 backend=nccl
[0;36m(EngineCore_DP0 pid=369523)[0;0m INFO 12-22 23:39:18 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=369523)[0;0m INFO 12-22 23:39:19 [gpu_model_runner.py:3467] Starting to load model ibm-granite/granite-4.0-h-small...
[0;36m(EngineCore_DP0 pid=369523)[0;0m INFO 12-22 23:39:19 [layer.py:379] Enabled separate cuda stream for MoE shared_experts
[0;36m(EngineCore_DP0 pid=369523)[0;0m INFO 12-22 23:39:20 [cuda.py:411] Using FLASH_ATTN attention backend out of potential backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 834, in run_engine_core
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 610, in __init__
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     super().__init__(
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         vllm_config, executor_class, log_stats, executor_fail_callback
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]                           ~~~~~~~~~~~~~~^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     self._init_executor()
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     self.driver_worker.load_model()
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3484, in load_model
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     self.model = model_loader.load_model(
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         vllm_config=self.vllm_config, model_config=self.model_config
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     model = initialize_model(
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         vllm_config=vllm_config, model_config=model_config
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     return model_class(vllm_config=vllm_config, prefix=prefix)
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 656, in __init__
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     self.model = GraniteMoeHybridModel(
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]                  ~~~~~~~~~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         vllm_config=vllm_config, prefix=maybe_prefix(prefix, "model")
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/compilation/decorators.py", line 291, in __init__
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     old_init(self, **kwargs)
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ~~~~~~~~^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 356, in __init__
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     self.start_layer, self.end_layer, self.layers = make_layers(
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]                                                     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         config.num_hidden_layers, get_layer, prefix=f"{prefix}.layers"
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/utils.py", line 606, in make_layers
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]                          ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 347, in get_layer
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     return layer_class(
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         config,
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         prefix=prefix,
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoehybrid.py", line 164, in __init__
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     self.block_sparse_moe = GraniteMoeMoE(
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]                             ~~~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         num_experts=config.num_local_experts,
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ...<4 lines>...
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         prefix=f"{prefix}.block_sparse_moe",
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/models/granitemoe.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     self.experts = FusedMoE(
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]                    ~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         num_experts=num_experts,
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ...<9 lines>...
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         is_sequence_parallel=self.is_sequence_parallel,
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     )
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/layer.py", line 652, in __init__
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     self.quant_method.create_weights(layer=self, **moe_quant_params)
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py", line 174, in create_weights
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     torch.empty(
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ~~~~~~~~~~~^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         num_experts,
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         ^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ...<2 lines>...
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         dtype=params_dtype,
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]         ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ),
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     ^
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]   File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=369523)[0;0m ERROR 12-22 23:39:21 [core.py:843] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 192.31 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.80 GiB is allocated by PyTorch, and 690.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Creating vLLM backend for model LocalModel.Granite4_0HSmall...
Creating vLLM backend for model ibm-granite/granite-4.0-h-small with 1 GPUs...
INFO 12-22 23:39:23 [model.py:637] Resolved architecture: GraniteMoeHybridForCausalLM
INFO 12-22 23:39:23 [model.py:1750] Using max model len 5000
INFO 12-22 23:39:23 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 12-22 23:39:23 [config.py:315] Disabling cascade attention since it is not supported for hybrid models.
INFO 12-22 23:39:23 [config.py:439] Setting attention block size to 528 tokens to ensure that attention page size is >= mamba page size.
INFO 12-22 23:39:23 [config.py:463] Padding mamba page size by 0.69% to ensure that mamba page size and attention page size are exactly equal.
[0;36m(EngineCore_DP0 pid=369585)[0;0m INFO 12-22 23:39:24 [core.py:93] Initializing a V1 LLM engine (v0.12.0) with config: model='ibm-granite/granite-4.0-h-small', speculative_config=None, tokenizer='ibm-granite/granite-4.0-h-small', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01), seed=0, served_model_name=ibm-granite/granite-4.0-h-small, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 256, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=369585)[0;0m INFO 12-22 23:39:25 [parallel_state.py:1200] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://141.142.254.49:49035 backend=nccl
[0;36m(EngineCore_DP0 pid=369585)[0;0m INFO 12-22 23:39:25 [parallel_state.py:1408] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
