warning: failed to save last-use data
This may prevent cargo from accurately tracking what is being used in its global cache. This information is used for automatically removing unused data in the cache.

database is locked

Caused by:
  Error code 5: The database file is locked
ðŸ”— Found pyo3 bindings
ðŸ Found CPython 3.13 at /projects/bfdz/zluo8/tool_and_judge2/.venv/bin/python
    Blocking waiting for file lock on build directory
warning: unused variable: `configs`
  --> src/lib.rs:16:29
   |
16 |     async fn tool_run_async(configs: Py<PyList>, num_gpus: usize) {
   |                             ^^^^^^^ help: if this is intentional, prefix it with an underscore: `_configs`
   |
   = note: `#[warn(unused_variables)]` on by default

warning: unused variable: `num_gpus`
  --> src/lib.rs:16:50
   |
16 |     async fn tool_run_async(configs: Py<PyList>, num_gpus: usize) {
   |                                                  ^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_num_gpus`

warning: `codebase_rs` (lib) generated 2 warnings
    Finished `release` profile [optimized] target(s) in 12.51s
ðŸ“– Found type stub file at codebase_rs.pyi
ðŸ“¦ Built wheel for CPython 3.13 to /tmp/.tmpLx11z4/codebase_rs-0.1.0-cp313-cp313-linux_x86_64.whl
ðŸ›  Installed codebase_rs-0.1.0
/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py:1041: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[0;36m(EngineCore_DP0 pid=33311)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=33311)[0;0m Loading safetensors checkpoint shards:  20% Completed | 1/5 [00:00<00:03,  1.09it/s]
[0;36m(EngineCore_DP0 pid=33311)[0;0m Loading safetensors checkpoint shards:  40% Completed | 2/5 [00:03<00:05,  1.70s/it]
[0;36m(EngineCore_DP0 pid=33311)[0;0m Loading safetensors checkpoint shards:  60% Completed | 3/5 [00:05<00:04,  2.21s/it]
[0;36m(EngineCore_DP0 pid=33311)[0;0m Loading safetensors checkpoint shards:  80% Completed | 4/5 [00:08<00:02,  2.44s/it]
[0;36m(EngineCore_DP0 pid=33311)[0;0m Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:11<00:00,  2.57s/it]
[0;36m(EngineCore_DP0 pid=33311)[0;0m Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:11<00:00,  2.32s/it]
[0;36m(EngineCore_DP0 pid=33311)[0;0m 
[0;36m(EngineCore_DP0 pid=33311)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|â–Š         | 3/35 [00:00<00:01, 21.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|â–ˆâ–‹        | 6/35 [00:00<00:01, 21.92it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|â–ˆâ–ˆâ–Œ       | 9/35 [00:00<00:01, 22.39it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|â–ˆâ–ˆâ–ˆâ–      | 12/35 [00:00<00:01, 22.95it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 15/35 [00:00<00:00, 22.92it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/35 [00:00<00:00, 23.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 21/35 [00:00<00:00, 24.08it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 24/35 [00:01<00:00, 24.46it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 27/35 [00:01<00:00, 24.99it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 30/35 [00:01<00:00, 25.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/35 [00:01<00:00, 25.35it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:01<00:00, 24.09it/s]
[0;36m(EngineCore_DP0 pid=33311)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 22.14it/s]Capturing CUDA graphs (decode, FULL):  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 24.21it/s]Capturing CUDA graphs (decode, FULL):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 25.04it/s]Capturing CUDA graphs (decode, FULL):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 25.62it/s]Capturing CUDA graphs (decode, FULL):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 26.04it/s]Capturing CUDA graphs (decode, FULL):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 26.46it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 25.75it/s]
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/judge.py", line 167, in <module>
    dispatch_preference_results(model_safe_name, config.lang1, config.lang2, combined_output_path)
                                                 ^^^^^^^^^^^^
AttributeError: 'builtins.JudgeConfig' object has no attribute 'lang1'
Exception ignored in: <function AsyncLLM.__del__ at 0x7f92e63a5a80>
Traceback (most recent call last):
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/async_llm.py", line 263, in __del__
  File "/projects/bfdz/zluo8/tool_and_judge2/.venv/lib/python3.13/site-packages/vllm/v1/engine/async_llm.py", line 268, in shutdown
TypeError: 'NoneType' object is not callable
